# 3. Deploy Streaming Application

In this exercise, we'll deploy two streaming applications.

## Concepts

Kafka Streams is an abstraction over producers and consumers that lets you ignore low-level details and focus on processing your Kafka data. Since it's declarative, processing code written in Kafka Streams is far more concise than the same code would be if written using the low-level Kafka clients.

Kafka Streams is a Java library: You write your code, create a JAR file, and then start your standalone application that streams records to and from Kafka (it doesn't run on the same node as the broker). You can run Kafka Streams on anything from a laptop all the way up to a large server.

## Build the Application

The KStreams Java applications are architected using: 

- Spring Boot
- Spring Cloud Stream
- Gradle for build management

We'll build two KStreams applications. The steps will be the same for each, executed in each application folder.


### 1) Build the Gradle Wrapper

To build a Gradle-based project, we need to have Gradle installed in our machine. However, if our installed version doesn't match with the project's version, we'll probably face many incompatibility problems.

Gradle Wrapper, also called Wrapper in short, solves this problem. It's a script that runs Gradle tasks with a declared version. If the declared version is not installed, Wrapper installs the required one.

```
cd /home/ubuntu/code/cfk-workshop/apps/datagen/
gradle wrapper
```

Once the command executes, you'll have a gradle wrapper script for your environment. 

```
ll /home/ubuntu/code/cfk-workshop/apps/datagen
...
-rwxrwxr-x 1 ubuntu ubuntu 5766 Aug 23 13:01 gradlew*
...
```

### 2) Build the application

```
# Use gradle wrapper to build
./gradlew clean assemble -x test --build-cache --quiet
# See the build output
ls /home/ubuntu/code/cfk-workshop/apps/datagen/build/libs
```

3) Build the application as a Docker image

```
# Build the Docker image locally (on this development machine)
./gradlew bootBuildImage --imageName=docker.io/<your_docker_id>/datagen

# Push the Docker image to Docker hub
docker push 

# View the images in local Docker
docker images
REPOSITORY                         TAG
rohit2b/datagen                    latest
```

### 4) Push your image to your Docker account

```
# Log in to your Docker account
docker login
Username: ...
Password: ***
# Push images to your Docker repository
docker push <your_docker_id>/datagen
```

Repeat steps 1-4 for the Wordcount application

```
cd /home/ubuntu/code/cfk-workshop/apps/wordcount/

gradle wrapper

./gradlew clean assemble -x test --build-cache --quiet

./gradlew bootBuildImage --imageName=docker.io/<your_docker_id>/wordcount

docker push <your_docker_id>/wordcount
```

## Deploy application to Minikube

Deploy the Datagen application.

```
cd /home/ubuntu/code/cfk-workshop/apps
kubectl apply -f /home/ubuntu/code/cfk-workshop/apps/datagen-app-secret.yaml
kubectl apply -f /home/ubuntu/code/cfk-workshop/apps/datagen-app-deployment.yaml
```

Your datagen application should be deployed.

```
# Check that application pod is up and running
kubectl get pods -n confluent

# Check that there are no errors in the application
kubectl logs -f datagen-quotes-0 -n confluent

# See that the topic has been created
kubectl get kafkaTopic -n confluent
```

Deploy the Wordcount application.

```
cd /home/ubuntu/code/cfk-workshop/apps
kubectl apply -f /home/ubuntu/code/cfk-workshop/apps/wordcount-app-secret.yaml
kubectl apply -f /home/ubuntu/code/cfk-workshop/apps/wordcount-app-deployment.yaml
```

Your wordcount application should be deployed.

```
# Check that application pod is up and running
kubectl get pods -n confluent

# Check that there are no errors in the application
kubectl logs-f wordcount-0 -n confluent

# See that the topic has been created
kubectl get kafkaTopic -n confluent
```

## View messages being produced through CLI

The datagen application writes messages to topic "quotes". This topic has been defined as a Kubernetes CustomResource:

```
kubectl describe kafkatopic quotes
```

Now, let's actually look at the contents of the topic. You'll ssh exec into the Kafka pod to avail of CLI tools.

Exec in to the Kafka pod

```
kubectl exec kafka-0 -it bash
```

Run the CLI consumer to read all topic messages:

```
kafka-console-consumer --bootstrap-server kafka.confluent.svc.cluster.local:9092 -topic quotes --from-beginning
```

## View messages in Control Center

Confluent Control Center is a GUI interface to monitor Confluent Platform.

Check to see what the Kubernetes service endpoint is for Control Center.

```
kubectl get svc
...
controlcenter                ClusterIP      None             <none>        9021/TCP,7203/TCP,7777/TCP,7778/TCP                              44m
controlcenter-0-internal     ClusterIP      10.108.70.244    <none>        9021/TCP,7203/TCP,7777/TCP,7778/TCP                              44m
...
```

Start a port forwarding to allow access to the Control Center GUI.

```
kubectl port-forward --address 0.0.0.0 svc/controlcenter-0-internal 9021:9021
```

Login in to http://localhost:9021 to access Control Center.

You now should be in the Control Center app.

1) Click on the cluster tile

2) Click on Topic in the left nav

3) Click on the topic name "quotes"

4) Go to messages

5) Click on the top right `cards` option.

Then, look at the stream of messages being produced.

Do the same for topic "counts".

## Review the applications and data

You've deployed two Kafka streams applications, that are built using Spring Boot.

The datagen application produces messages that contain quotes from a movie to a topic "quotes".

The wordcount application consumes those messages from the topic "quotes", processes them and determines the counts of specific words in the messages, and then writes the counts for each word to the topic "counts".

Review the code for both applications to get a more in-depth understanding:

```
vi /home/ubuntu/code/cfk-workshop/apps/datagen/src/main/java/io/confluent/developer/datagen/DatagenApplication.java
vi /home/ubuntu/code/cfk-workshop/apps/wordcount/src/main/java/io/confluent/developer/datagen/WordcountApplication.java
```

## Learn More

Learn more about Kafka streams at Check out https://developer.confluent.io/learn-kafka/kafka-streams/get-started/

Learn more about Spring Boot at https://spring.io/projects/spring-boot

Learn more about Spring Cloud Stream at https://spring.io/projects/spring-cloud-stream
